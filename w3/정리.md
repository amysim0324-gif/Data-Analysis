# Overfitting and Underfitting

- 샘플의 수가 적으면 **오버피팅** 발생 가능성 ↑  
- **오버피팅**: 모의고사 98점, 실전 70점  
- **언더피팅**: 학습 부족 → 모의고사와 실전시험 모두 성적 낮음  
- 연속된 수치 데이터를 범주형으로 변환하여 오버피팅 방지  

---

# 결측치 처리

```python
df.isnull().sum()
결과가 0으로 나오면 결측치가 없는 상태

0 값을 null로 간주하고 싶으면 새로운 열 생성

python
코드 복사
df["Insulin_nan"] = df["Insulin"].replace(0, np.nan)
결측치 수를 세기 위해 Insulin_nan 열 사용

결측치가 많으면 학습 시 오류 발생 가능

Feature Importance 시각화
python
코드 복사
sns.barplot(x=model.feature_importances_, y=feature_names)
데이터 분포와 Log 변환
한쪽으로 데이터가 몰리면 학습 어려움 발생

Log 변환 → 정규분포와 유사한 분포로 변환

0 이하 값은 음의 무한대로 수렴 → +1 보정 필요

python
코드 복사
sns.distplot(np.log(df.loc[df["Insulin"] > 0, "Insulin"] + 1))
Log 변환 = 성능 향상 보장 ❌

이상치 확인 (Outlier Detection)
python
코드 복사
sns.boxplot(df["Insulin_nan"])
스케일링 (Scaling)
숫자 범위 차이 → feature 비중 왜곡

Scaling 기법 사용

fit + transform → 값 변환 → 예측 정확도 ↑

Train/Test 데이터셋 분리
python
코드 복사
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
모델 튜닝
Max Depth
max_depth 조정 시 성능 ↑

트리가 너무 얕으면 → 언더피팅 발생

GridSearchCV
하이퍼파라미터 튜닝 기법

Cross Validation: train 데이터를 여러 fold로 나눠 평균 성능 측정

python
코드 복사
from sklearn.model_selection import GridSearchCV

grid = GridSearchCV(
    estimator=model,
    param_grid={"max_depth": [3, 5, 7]},
    cv=5,
    n_jobs=-1
)
grid.fit(X_train, y_train)
max_features: 일부 feature만 사용 (1 = 전체 feature 사용)

cv_results_: cross validation 결과 DataFrame 반환

RandomizedSearchCV
하이퍼파라미터 랜덤 탐색

param_distributions 정의 후 랜덤 샘플링

random_state: 결과 고정

python
코드 복사
from sklearn.model_selection import RandomizedSearchCV

random_search = RandomizedSearchCV(
    estimator=model,
    param_distributions={"max_depth": [3, 5, 7, 9]},
    n_iter=10,
    cv=5,
    random_state=42,
    n_jobs=-1
)
random_search.fit(X_train, y_train)
GridSearchCV → 정해진 범위 탐색
RandomizedSearchCV → 랜덤 탐색 (더 넓은 후보군에서 최적 찾을 수 있음)
