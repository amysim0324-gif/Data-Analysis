## 머신러닝 모델 학습 및 최적화

---

### 1. 오버피팅과 언더피팅
* [cite_start]**오버피팅(Overfitting)**: 모델이 학습 데이터에 지나치게 맞춰져서, 실제 데이터(실전)에서는 성능이 떨어지는 현상입니다[cite: 3].
    * [cite_start]**예시**: 모의고사 점수는 98점인데 실제 시험 점수는 70점인 경우[cite: 3].
    * [cite_start]**원인**: 샘플 수가 적을 때 발생할 가능성이 높습니다[cite: 2].
* [cite_start]**언더피팅(Underfitting)**: 모델이 학습이 덜 되어서 학습 데이터와 실제 데이터 모두에서 성능이 낮은 현상입니다[cite: 4].
    * [cite_start]**예시**: 공부를 충분히 하지 않아 모의고사와 실제 시험을 모두 못 본 경우[cite: 4].
    * [cite_start]**원인**: 트리의 깊이가 너무 얕을 때 발생할 수 있습니다[cite: 24].

### 2. 데이터 전처리
* **결측치(Missing Values) 처리**:
    * [cite_start]`Df.isnull().sum()`을 사용해 결측치 수를 확인할 수 있습니다[cite: 6].
    * [cite_start]만약 결과가 0으로 나왔는데 실제로는 결측치가 있는 경우, 0값을 **Null**로 바꾸어 새로운 열(`Insulin_nan`)을 만들어야 정확한 결측치 수를 셀 수 있습니다[cite: 7, 8].
    * [cite_start]결측치가 너무 많으면 학습 시 오류가 발생할 수 있습니다[cite: 9].
* **데이터 분포 변환**:
    * [cite_start]`Log` 변환을 사용하면 데이터 분포가 정규 분포와 비슷하게 변합니다[cite: 12].
    * [cite_start]이때 0 이하의 값은 음의 무한대에 수렴하므로 `+1`을 더해줘야 합니다[cite: 13].
        * [cite_start]**코드 예시**: `sns.distplot(np.log(df.loc[df["Insulin"]>0, "Insulin"]+1))` [cite: 14]
    * [cite_start]단, `Log` 변환이 항상 모델의 성능을 향상시키는 것은 아닙니다[cite: 15].
* **이상치(Outliers) 처리**:
    * [cite_start]`sns.boxplot()`을 사용해 **상자 수염 그림**을 그리면 이상치를 시각적으로 확인할 수 있습니다[cite: 16].
* **스케일링(Scaling)**:
    * [cite_start]피처(feature)별로 값의 범위가 다르면 학습 시 가중치가 다르게 계산될 수 있으므로 **스케일링 기법**을 사용해야 합니다[cite: 17].
    * [cite_start]`fit`과 `transform`을 통해 숫자를 변형하며, 이를 통해 예측 정확도를 높일 수 있습니다[cite: 18, 19].
    * [cite_start]연속된 수치형 데이터를 범주형으로 바꾸어 오버피팅을 방지할 수 있습니다[cite: 5].

### 3. 모델 학습 및 평가
* **데이터셋 분할**:
    * [cite_start]`sklearn.model_selection`의 `train_test_split`을 이용해 학습용(`train`)과 평가용(`test`) 데이터셋을 나눌 수 있습니다[cite: 20, 21].
    * [cite_start]**코드 예시**: `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)` [cite: 22, 23]
* **피처 중요도 시각화**:
    * [cite_start]`sns.barplot(x=model.feature_importances_, y=feature_names)` 코드를 사용해 피처의 중요도를 시각화할 수 있습니다[cite: 10].
    * [cite_start]한쪽에만 데이터가 몰려 있으면 학습에 어려움이 있을 수 있습니다[cite: 11].

### 4. 모델 성능 튜닝
* **하이퍼 파라미터 튜닝**:
    * [cite_start]`max_depth` 값을 조절하면 모델의 성능을 향상시킬 수 있습니다[cite: 24].
    * **GridSearchCV**:
        * [cite_start]미리 설정한 범위 안의 모든 파라미터 조합을 탐색하여 최적의 값을 찾습니다[cite: 25, 32].
        * [cite_start]`param_grid`에 튜닝하고 싶은 파라미터 정보를 담아 사용합니다[cite: 27].
        * [cite_start]`cv_results_`를 사용하면 교차 검증(`cross validation`) 결과를 데이터프레임으로 확인할 수 있습니다[cite: 26, 30].
    * **RandomizedSearchCV**:
        * [cite_start]설정한 범위 내에서 무작위로 파라미터 조합을 탐색하여 최적의 값을 찾습니다[cite: 31, 32].
        * [cite_start]`param_distributions`을 정의하여 랜덤한 값을 넣습니다[cite: 33].
    * **공통 설정**:
        * [cite_start]`max_features`는 1로 설정하면 모든 피처를 사용한다는 의미입니다[cite: 28].
        * [cite_start]`n_jobs`를 `-1`로 설정하면 사용 가능한 모든 장비를 학습에 이용할 수 있습니다[cite: 29].
        * [cite_start]`random_state`는 값을 고정하는 역할을 합니다[cite: 34].
